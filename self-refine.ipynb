{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Refine Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dashscope\n",
      "  Using cached dashscope-1.22.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (3.10.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (2.32.3)\n",
      "Requirement already satisfied: websocket-client in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (5.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->dashscope) (4.11.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->dashscope) (0.2.0)\n",
      "Using cached dashscope-1.22.2-py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: dashscope\n",
      "Successfully installed dashscope-1.22.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dashscope.exe is installed in 'C:\\Users\\ab-in\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dashscope python-dotenv urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dashscope\n",
    "import sys\n",
    "import platform\n",
    "import dashscope\n",
    "import time\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from typing import Tuple, Optional, Dict, Union\n",
    "from dashscope.api_entities.dashscope_response import Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Current environment information\n",
      "----------------------------------------\n",
      "Python version: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]\n",
      "Platform system: Windows 10\n",
      "DASHSCOPE_API_KEY read successfully: âœ… Yes\n"
     ]
    }
   ],
   "source": [
    "# 1) Load environment (DASHSCOPE_API_KEY)\n",
    "\n",
    "load_dotenv(\"dashscope_api_key.env\")\n",
    "api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"DASHSCOPE_API_KEY not found!\")\n",
    "\n",
    "# Print environment information\n",
    "print(\"Current environment information\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform system: {platform.system()} {platform.release()}\")\n",
    "print(f\"DASHSCOPE_API_KEY read successfully: {'âœ… Yes' if api_key else 'âŒ No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Call Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(\n",
    "    prompt: str,\n",
    "    model_name: str = \"qwen2.5-math-1.5b-instruct\",\n",
    "    system_prompt: str = (\n",
    "        \"You are a helpful and precise math tutor. \"\n",
    "        \"Always solve the problem step-by-step. \"\n",
    "        \"Then, at the very end of your answer, write on a new line:\\n\"\n",
    "        \"**Final Answer: <your numeric result>**\\n\"\n",
    "        \"Do not forget this final answer format. It is required.\"\n",
    "    ),\n",
    "    temperature: float = 0.7,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: float = 1.0,\n",
    "    verbose: bool = False\n",
    ") -> Tuple[Optional[str], Optional[dict]]:\n",
    "    \"\"\"\n",
    "    Call Qwen via DashScope with retry support and structured prompt.\n",
    "    Returns (content, usage) if successful, else (None, None).\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"DASHSCOPE_API_KEY not found!\")\n",
    "        return None, None\n",
    "\n",
    "    messages = [\n",
    "        Message(role=\"system\", content=system_prompt),\n",
    "        Message(role=\"user\", content=prompt)\n",
    "    ]\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = dashscope.Generation.call(\n",
    "                api_key=api_key,\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                result_format=\"message\",\n",
    "                timeout=60\n",
    "            )\n",
    "\n",
    "            status_code = response[\"status_code\"]  # type: ignore\n",
    "            if status_code == 429:\n",
    "                print(f\"âš ï¸[Attempt {attempt}/{max_retries}] Rate limit! Retrying in {retry_delay}s...\")\n",
    "                time.sleep(retry_delay)\n",
    "                continue\n",
    "\n",
    "            content = response[\"output\"][\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n",
    "            usage = response.get(\"usage\", {})  # type: ignore\n",
    "            # if verbose:\n",
    "            #     print(\"Prompt:\\n\", prompt)\n",
    "            #     print(\"\\nModel Response:\\n\", content)\n",
    "            #     print(\"\\nToken Usage:\", usage)\n",
    "            #     print(response)\n",
    "            return content, usage\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸[Attempt {attempt}/{max_retries}] Exception occurred: {e}\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    print(f\"All {max_retries} attempts failed.\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"To determine how many cupcakes the baker has left, we need to follow these steps:\\n\\n1. Start with the initial number of cupcakes the baker has, which is 20.\\n2. Subtract the number of cupcakes the baker eats, which is 2.\\n3. Subtract the number of cupcakes the baker gives away, which is 3.\\n\\nLet's perform the calculations step-by-step:\\n\\n1. Initial number of cupcakes: 20\\n2. After eating 2 cupcakes: \\\\(20 - 2 = 18\\\\)\\n3. After giving away 3 cupcakes: \\\\(18 - 3 = 15\\\\)\\n\\nSo, the number of cupcakes the baker has left is \\\\(\\\\boxed{15}\\\\).\",\n",
       " GenerationUsage(input_tokens=102, output_tokens=149))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"A baker makes 20 cupcakes. He eats 2 and gives away 3. How many does he have left?\"\n",
    "\n",
    "content, usage = call_model(\n",
    "    prompt=f\"Solve the following problem step-by-step:\\n{question}\",\n",
    "    verbose=True\n",
    ")\n",
    "content, usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_answer(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the final numeric or concise answer from the given response text.\n",
    "\n",
    "    The order of priority is as follows:\n",
    "    1. Check \"Final Answer: ...\" (case-insensitive).\n",
    "    2. Check the last occurrence of \"\\boxed{...}\" (LaTeX style). From that box, parse advanced numeric forms.\n",
    "    3. If no box found or no valid numeric in it, scan the entire text for the last recognized numeric form.\n",
    "    4. If nothing is found at all, return the entire trimmed response text.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) Check for \"Final Answer: ...\"\n",
    "    #    (Now has the highest priority)\n",
    "    # ----------------------------\n",
    "    fa_match = re.search(r\"(?i)final answer\\s*:\\s*([^\\n]+)\", response_text)\n",
    "    if fa_match:\n",
    "        candidate = fa_match.group(1).strip()\n",
    "        # If we want to parse advanced numeric forms from this candidate,\n",
    "        # we can do so here. Otherwise, we return directly.\n",
    "        return candidate\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Check for the last occurrence of \"\\boxed{...}\"\n",
    "    #    We'll parse advanced numeric forms from within it.\n",
    "    #    If multiple boxes exist, we take the last one.\n",
    "    # ----------------------------\n",
    "    # Regex to match all \\boxed{...} blocks (including nested braces is tricky, but we do a simple approach)\n",
    "    all_boxes = re.findall(r\"\\\\boxed\\{([^}]*)\\}\", response_text, flags=re.DOTALL)\n",
    "    if all_boxes:\n",
    "        box_content = all_boxes[-1]  # take the last box\n",
    "        # Try to parse advanced numeric forms from the box content\n",
    "        numbers_in_box = parse_numeric_expressions(box_content)\n",
    "        if numbers_in_box:\n",
    "            # If multiple numbers found, return the last one\n",
    "            return numbers_in_box[-1].strip()\n",
    "        # If no recognized numeric, return the raw content\n",
    "        return box_content.strip()\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) Fallback: parse the entire text for recognized numeric forms\n",
    "    #    Return the last one if available.\n",
    "    # ----------------------------\n",
    "    all_numbers = parse_numeric_expressions(response_text)\n",
    "    if all_numbers:\n",
    "        return all_numbers[-1].strip()\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) Final fallback: return entire string\n",
    "    # ----------------------------\n",
    "    return response_text.strip()\n",
    "\n",
    "\n",
    "def parse_numeric_expressions(text: str):\n",
    "    \"\"\"\n",
    "    Parse various numeric expressions from the text, including:\n",
    "    - Optional sign: [+/-]\n",
    "    - Integers or decimals (e.g., 123, -3.14)\n",
    "    - Simple LaTeX fraction: \\frac{number}{number}\n",
    "\n",
    "    Returns a list of all matched string forms in order of appearance.\n",
    "    \"\"\"\n",
    "    # We'll combine a few patterns:\n",
    "    # 1) signed integer or decimal: [+-]?\\d+(?:\\.\\d+)?\n",
    "    # 2) simple fraction form: \\frac\\s*\\{?\\s*[+-]?\\d+(\\.\\d+)?\\s*\\}?\\s*/\\s*\\{?\\s*[+-]?\\d+(\\.\\d+)?\\s*\\}?\n",
    "    pattern = r\"\"\"\n",
    "        [+-]?\\d+(?:\\.\\d+)?              # e.g. -3, 4.5, +2.0\n",
    "        |\n",
    "        \\\\frac\\s*\\{?\\s*[+-]?\\d+(?:\\.\\d+)?\\s*\\}?\\s*/\\s*\\{?\\s*[+-]?\\d+(?:\\.\\d+)?\\s*\\}?  # e.g. \\frac{3}{5}, \\frac{-2.5}{10}\n",
    "    \"\"\"\n",
    "\n",
    "    # Using VERBOSE flag to allow inline comments\n",
    "    matches = re.findall(pattern, text, flags=re.VERBOSE)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Self-Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Refine: Iterative Feedback and Refinement\n",
    "\n",
    "The **`self_refine`** function is designed to generate and refine a solution for a mathematical problem using multiple rounds of self-critique and improvement. It carefully orchestrates how the model:\n",
    "\n",
    "1. **Produces an Initial Draft**  \n",
    "   - The function prompts the model to solve the math problem in a rigorous, step-by-step manner.\n",
    "   - This initial draft serves as the baseline that will be critiqued in the subsequent steps.\n",
    "\n",
    "2. **Generates Feedback**  \n",
    "   - In each round, the model is presented with its own prior output (the â€œdraft answerâ€) along with the original problem.\n",
    "   - It is asked to analyze correctness, clarity, and completeness, suggesting specific improvements if errors are found.  \n",
    "   - If the model indicates â€œno improvement needed,â€ and at least one round of refinement has already occurred, the process may stop early.\n",
    "\n",
    "3. **Refines the Answer**  \n",
    "   - Following the feedback, the model refines its previous draft to address the identified gaps or errors.\n",
    "   - This new refined answer replaces the old draft and can be further iterated upon if additional rounds are available or required.\n",
    "\n",
    "4. **At-Least-One-Round Condition**  \n",
    "   - The function ensures that the model goes through at least one refinement cycle. If the model declares â€œeverything is correctâ€ on the very first round, the function still carries out that round to solidify an improved version of the draft (if needed) before checking for early termination.\n",
    "\n",
    "5. **Early Stopping**  \n",
    "   - In subsequent rounds (after the first has completed), if the modelâ€™s feedback repeatedly indicates no more changes are necessary or the draft is already correct, the iteration halts. This â€œearly stoppingâ€ heuristic reduces unnecessary computation.\n",
    "\n",
    "6. **Usage and Round Tracking**  \n",
    "   - Every call to the model (for either feedback or refinement) accumulates usage dataâ€”such as the total token countâ€”into a running total.\n",
    "   - The function also records which round triggered the exit, whether due to reaching the maximum number of allowed rounds or stopping early after an â€œall goodâ€ declaration.\n",
    "\n",
    "7. **Extracting the Final Answer**  \n",
    "   - Once the iterations conclude, the final, refined text is passed through a function (e.g., `extract_final_answer`) to parse out the numeric result or short answer if desired.\n",
    "   - This extracted value, along with the full refined text, the total token usage, and the index of the last refinement round, is returned to the caller.\n",
    "\n",
    "### Key Points & Considerations\n",
    "\n",
    "- **Rigorous System Prompt**  \n",
    "  - The model is cast in the role of a â€œrigorous math tutor,â€ ensuring detailed reasoning and clarity in every generation.\n",
    "  - >Since both temperature and top_p can control the diversity of generated text, it is recommended that you only set one of them. \n",
    "    - So I lowered the temperature a bit, reduced the diversity appropriately, and ensured the rigor of the mathematical results.\n",
    "\n",
    "- **Feedback-Refine Loop**  \n",
    "  The model alternates between critiquing its own output and improving it, thereby aiming to catch logical or computational mistakes in a structured manner.\n",
    "\n",
    "- **Mandatory Improvement Round**  \n",
    "  The function will not accept an immediate â€œno improvementâ€ response for the first refinement attempt. This ensures that, at a minimum, the model has made one pass to reevaluate its initial draft.\n",
    "\n",
    "- **Early Stop Heuristic**  \n",
    "  After at least one refinement, if the model states that no further changes are needed, the loop terminates early. This method is a convenience to reduce overhead when the model is sufficiently confident.\n",
    "\n",
    "- **No Absolute Guarantee of Correctness**  \n",
    "  While the approach often enhances solution quality, the modelâ€™s own judgment may still fail to catch subtler errors. For high-stakes scenarios, external validation (e.g., test suites or domain experts) is recommended.\n",
    "\n",
    "- **Return Structure**  \n",
    "  The final output includes:\n",
    "  1. **`final_text`**: The modelâ€™s last refined draft (full textual answer).  \n",
    "  2. **`final_answer`**: The numeric or short result extracted from `final_text`.  \n",
    "  3. **`ended_on_round`**: Which round triggered the exit, either because of reaching the maximum iteration or early stopping.  \n",
    "  4. **`total_usage`**: A cumulative usage metric (e.g., total tokens).\n",
    "\n",
    "This procedure illustrates a practical way to nudge large language models toward more self-critical and iteratively improved answers, particularly for math-oriented tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_refine(\n",
    "    question: str,\n",
    "    rounds: int = 3,\n",
    "    verbose: bool = True,\n",
    "    model_name: str = \"qwen2.5-math-1.5b-instruct\",\n",
    "    temperature: float = 0.2,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Conduct multiple rounds of 'Self-Refine' for a math problem, returning the final refined answer.\n",
    "\n",
    "    Args:\n",
    "        question (str): The math problem to be solved.\n",
    "        rounds (int): The maximum number of refinement iterations.\n",
    "        verbose (bool): Whether to print intermediate steps.\n",
    "        model_name (str): The name of the language model to call.\n",
    "        temperature (float): Sampling temperature for controlling randomness in the output.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          {\n",
    "              \"final_text\"      : str or None, \n",
    "              \"final_answer\"    : str or None,\n",
    "              \"ended_on_round\"  : int,\n",
    "              \"total_usage\"     : int  # or float, depending on actual usage measure\n",
    "          }\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # System prompt (for rigorous step-by-step math reasoning)\n",
    "    # -----------------------------\n",
    "    system_prompt = (\n",
    "        \"You are a rigorous math tutor. \"\n",
    "        \"You solve problems step by step in detail and ensure mathematical correctness. \"\n",
    "        \"Then, at the end, on a new line, write:\\n\"\n",
    "        \"Final Answer: <numeric result>\\n\"\n",
    "        \"Do not include any additional text after that line.\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Template for the initial draft generation\n",
    "    # -----------------------------\n",
    "    first_prompt_template = (\n",
    "        \"Solve the following math problem with detailed reasoning. \"\n",
    "        \"Explain your steps clearly and logically. \"\n",
    "        \"At the end, please write:\\n\"\n",
    "        \"Final Answer: <number>\\n\\n\"\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Template for generating feedback about the draft answer\n",
    "    # -----------------------------\n",
    "    feedback_prompt_template = (\n",
    "        \"Below is a math problem and a draft solution:\\n\\n\"\n",
    "        \"Problem:\\n{question}\\n\\n\"\n",
    "        \"Draft Answer:\\n{draft}\\n\\n\"\n",
    "        \"Please analyze the draft solution for correctness, clarity, and completeness. \"\n",
    "        \"Point out any errors or omissions, and suggest specific improvements. \"\n",
    "        \"If the solution is already correct and needs no improvement, state that explicitly.\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Template for refining the draft answer based on feedback\n",
    "    # -----------------------------\n",
    "    refine_prompt_template = (\n",
    "        \"Here is a math problem, a draft solution, and some feedback:\\n\\n\"\n",
    "        \"Problem:\\n{question}\\n\\n\"\n",
    "        \"Draft Answer:\\n{draft}\\n\\n\"\n",
    "        \"Feedback:\\n{feedback}\\n\\n\"\n",
    "        \"Please refine the draft solution to correct errors and address the feedback. \"\n",
    "        \"At the end, write 'Final Answer: <number>'. \"\n",
    "        \"Ensure the steps are logically sound and the numeric result is correct.\"\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # 0) Setup usage tracking, etc.\n",
    "    # =============================\n",
    "    total_usage_tokens = 0\n",
    "    ended_on_round = 0\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Generate the initial draft\n",
    "    # -----------------------------\n",
    "    init_prompt = first_prompt_template.format(question=question)\n",
    "    draft, usage_init = call_model(\n",
    "        prompt=init_prompt,\n",
    "        model_name=model_name,\n",
    "        system_prompt=system_prompt,\n",
    "        temperature=temperature,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    if usage_init is None:\n",
    "        usage_init = {\"total_tokens\": 0}\n",
    "    total_usage_tokens += usage_init['total_tokens']\n",
    "\n",
    "    if draft is None:\n",
    "        if verbose:\n",
    "            print(\"âŒ[Error] Initial draft generation returned None.\")\n",
    "        return {\n",
    "            \"final_text\": None,\n",
    "            \"final_answer\": None,\n",
    "            \"ended_on_round\": 0,\n",
    "            \"total_usage\": total_usage_tokens\n",
    "        }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nâœ…â”â” [Initial Draft Generated] â”â”âœ…\")\n",
    "        print(draft)\n",
    "        print(\"\")  # Extra line\n",
    "\n",
    "    current_answer = draft\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) Iterative refinement\n",
    "    # -----------------------------\n",
    "    for i in range(rounds):\n",
    "        round_index = i + 1\n",
    "        if verbose:\n",
    "            print(f\"[Refinement Round {i+1} of {rounds}]\")\n",
    "\n",
    "        # 2a) Generate feedback\n",
    "        feedback_prompt = feedback_prompt_template.format(\n",
    "            question=question,\n",
    "            draft=current_answer\n",
    "        )\n",
    "        feedback, usage_fb = call_model(\n",
    "            prompt=feedback_prompt,\n",
    "            model_name=model_name,\n",
    "            system_prompt=system_prompt,\n",
    "            temperature=temperature,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        if usage_fb is None:\n",
    "            usage_fb = {\"total_tokens\": 0}\n",
    "        total_usage_tokens += usage_fb['total_tokens']\n",
    "\n",
    "        if feedback is None:\n",
    "            if verbose:\n",
    "                print(\"âŒ[Error] Feedback generation returned None. Stopping refinement.\")\n",
    "            ended_on_round = round_index\n",
    "            break\n",
    "\n",
    "        if verbose:\n",
    "            print(\"âœ… [Feedback Received]\")\n",
    "            print(feedback)\n",
    "            print(\"\")\n",
    "\n",
    "        # 2b) Check if feedback suggests no improvement, at least one round.\n",
    "        lower_fb = feedback.lower()\n",
    "        if round_index > 1 and (\"no improvement\" in lower_fb or \"solution is correct\" in lower_fb or \"already correct\" in lower_fb):\n",
    "            if verbose:\n",
    "                print(\"âœ…[Notice] Feedback indicates no further improvement is needed. Stopping early.\")\n",
    "            ended_on_round = round_index\n",
    "            break\n",
    "\n",
    "        # 2c) Refine the answer\n",
    "        refine_prompt = refine_prompt_template.format(\n",
    "            question=question,\n",
    "            draft=current_answer,\n",
    "            feedback=feedback\n",
    "        )\n",
    "        refined, usage_refine = call_model(\n",
    "            prompt=refine_prompt,\n",
    "            model_name=model_name,\n",
    "            system_prompt=system_prompt,\n",
    "            temperature=temperature,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        if usage_refine is None:\n",
    "            usage_refine = {\"total_tokens\": 0}\n",
    "        total_usage_tokens += usage_refine['total_tokens']\n",
    "\n",
    "        if refined is None:\n",
    "            if verbose:\n",
    "                print(\"âš ï¸[Warning] Refinement returned None. Using current version and stopping.\")\n",
    "            ended_on_round = round_index\n",
    "            break\n",
    "\n",
    "        current_answer = refined  # Update the answer\n",
    "        if verbose:\n",
    "            print(\"âœ… [Refined Answer]\")\n",
    "            print(current_answer)\n",
    "            print(\"\")\n",
    "            \n",
    "        ended_on_round = round_index  # if we never break, we'll end after final iteration\n",
    "\n",
    "    # =============================\n",
    "    # 3) Extract final numeric answer if requested\n",
    "    # =============================\n",
    "    final_answer = extract_final_answer(current_answer)\n",
    "\n",
    "    # =============================\n",
    "    # 4) Return collected info\n",
    "    # =============================\n",
    "    return {\n",
    "        \"final_text\": current_answer,\n",
    "        \"final_answer\": final_answer,\n",
    "        \"ended_on_round\": ended_on_round,\n",
    "        \"total_usage\": total_usage_tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Single Demo Question Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ…â”â” [Initial Draft Generated] â”â”âœ…\n",
      "To determine how much Janet makes every day at the farmers' market, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid by the ducks each day.\n",
      "2. Determine how many eggs Janet eats for breakfast and bakes for her friends.\n",
      "3. Find out how many eggs are left for sale at the farmers' market.\n",
      "4. Calculate the revenue from selling these eggs at $2 per egg.\n",
      "\n",
      "Let's start with the first step:\n",
      "\n",
      "1. The total number of eggs laid by the ducks each day is 16.\n",
      "\n",
      "2. Janet eats 3 eggs for breakfast every morning and bakes 4 eggs for her friends every day. So, the total number of eggs she uses or sells immediately is:\n",
      "   \\[\n",
      "   3 + 4 = 7 \\text{ eggs}\n",
      "   \\]\n",
      "\n",
      "3. The number of eggs left for sale at the farmers' market is:\n",
      "   \\[\n",
      "   16 - 7 = 9 \\text{ eggs}\n",
      "   \\]\n",
      "\n",
      "4. Since each egg is sold for $2, the revenue from selling 9 eggs is:\n",
      "   \\[\n",
      "   9 \\times 2 = 18 \\text{ dollars}\n",
      "   \\]\n",
      "\n",
      "Therefore, the amount Janet makes every day at the farmers' market is:\n",
      "\\[\n",
      "\\boxed{18}\n",
      "\\]\n",
      "\n",
      "[Refinement Round 1 of 3]\n",
      "âœ… [Feedback Received]\n",
      "The draft solution is correct and complete. It follows the steps logically and provides the final answer clearly. There are no errors or omissions. Therefore, no changes are needed.\n",
      "\n",
      "The final answer is:\n",
      "\\[\n",
      "\\boxed{18}\n",
      "\\]\n",
      "\n",
      "âœ…[Notice] Feedback indicates no further improvement is needed. Stopping early.\n",
      "\n",
      "â”â”â” â˜…  SINGLE QUESTION TEST  â˜… â”â”â”\n",
      "ğŸ“Œ  Question:\n",
      "Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "\n",
      "ğŸ’¡  Predicted Final Answer: 18\n",
      "ğŸ¯  Gold Answer: 18\n",
      "âœ…  Correct? True\n",
      "ğŸ”  Response Length (chars): 978\n",
      "ğŸŒ€  Ended on Round: 1\n",
      "ğŸ“Š  Total Usage (tokens): 936\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "\n",
    "    # Gold answer\n",
    "    gold_answer = \"18\"\n",
    "\n",
    "    # Do self-consistency\n",
    "    result = self_refine(\n",
    "        question=question,\n",
    "        model_name=\"qwen2.5-math-1.5b-instruct\",\n",
    "        rounds=3\n",
    "    )\n",
    "    final_text = result[\"final_text\"]\n",
    "    final_answer = result[\"final_answer\"]\n",
    "    ended_on_round = result[\"ended_on_round\"]\n",
    "    total_usage = result[\"total_usage\"]\n",
    "\n",
    "    # Compare with gold\n",
    "    is_correct = (final_answer.strip() == gold_answer.strip())\n",
    "    response_length = len(final_text)\n",
    "\n",
    "    \n",
    "    # Print the info\n",
    "    print(\"\\nâ”â”â” â˜…  SINGLE QUESTION TEST  â˜… â”â”â”\")\n",
    "    print(f\"ğŸ“Œ  Question:\\n{question}\\n\")\n",
    "    print(f\"ğŸ’¡  Predicted Final Answer: {final_answer}\")\n",
    "    print(f\"ğŸ¯  Gold Answer: {gold_answer}\")\n",
    "    print(f\"âœ…  Correct? {is_correct}\")\n",
    "    print(f\"ğŸ”  Response Length (chars): {response_length}\")\n",
    "    print(f\"ğŸŒ€  Ended on Round: {ended_on_round}\")\n",
    "    print(f\"ğŸ“Š  Total Usage (tokens): {total_usage}\")\n",
    "    print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
