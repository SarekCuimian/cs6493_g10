{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== Evaluating Model: qwen2.5-math-1.5b-instruct ====================\n",
      "üîÅ Resuming from existing result file: results/self_consistency_math500_qwen.csv\n",
      "\n",
      "=== Evaluating question at index 2 ===\n",
      "Question: If $f(x) = \\frac{3x-2}{x-2}$, what is the value of $f(-2) +f(-1)+f(0)$? Express your answer as a common fraction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 189\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample_i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(samples_per_question):\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 189\u001B[0m         output, usage \u001B[38;5;241m=\u001B[39m call_model(\n\u001B[1;32m    190\u001B[0m             prompt\u001B[38;5;241m=\u001B[39mquestion,\n\u001B[1;32m    191\u001B[0m             model_name\u001B[38;5;241m=\u001B[39mmodel_name,\n\u001B[1;32m    192\u001B[0m             temperature\u001B[38;5;241m=\u001B[39mtemperature,\n\u001B[1;32m    193\u001B[0m             top_p\u001B[38;5;241m=\u001B[39mtop_p\n\u001B[1;32m    194\u001B[0m         )\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    196\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Error in call_model] \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[18], line 35\u001B[0m, in \u001B[0;36mcall_model\u001B[0;34m(prompt, model_name, system_prompt, temperature, top_p, max_retries, retry_delay)\u001B[0m\n\u001B[1;32m     30\u001B[0m messages \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     31\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: system_prompt},\n\u001B[1;32m     32\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt}\n\u001B[1;32m     33\u001B[0m ]\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_retries):\n\u001B[0;32m---> 35\u001B[0m     response \u001B[38;5;241m=\u001B[39m dashscope\u001B[38;5;241m.\u001B[39mGeneration\u001B[38;5;241m.\u001B[39mcall(\n\u001B[1;32m     36\u001B[0m         api_key\u001B[38;5;241m=\u001B[39mapi_key,\n\u001B[1;32m     37\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel_name,\n\u001B[1;32m     38\u001B[0m         messages\u001B[38;5;241m=\u001B[39mmessages,\n\u001B[1;32m     39\u001B[0m         temperature\u001B[38;5;241m=\u001B[39mtemperature,\n\u001B[1;32m     40\u001B[0m         top_p\u001B[38;5;241m=\u001B[39mtop_p,\n\u001B[1;32m     41\u001B[0m         result_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     42\u001B[0m     )\n\u001B[1;32m     43\u001B[0m     status_code \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m429\u001B[39m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/dashscope/aigc/generation.py:138\u001B[0m, in \u001B[0;36mGeneration.call\u001B[0;34m(cls, model, prompt, history, api_key, messages, plugins, workspace, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m headers\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28minput\u001B[39m, parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_build_input_parameters(\n\u001B[1;32m    137\u001B[0m     model, prompt, history, messages, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 138\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcall(model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    139\u001B[0m                         task_group\u001B[38;5;241m=\u001B[39mtask_group,\n\u001B[1;32m    140\u001B[0m                         task\u001B[38;5;241m=\u001B[39mGeneration\u001B[38;5;241m.\u001B[39mtask,\n\u001B[1;32m    141\u001B[0m                         function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[1;32m    142\u001B[0m                         api_key\u001B[38;5;241m=\u001B[39mapi_key,\n\u001B[1;32m    143\u001B[0m                         \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    144\u001B[0m                         workspace\u001B[38;5;241m=\u001B[39mworkspace,\n\u001B[1;32m    145\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparameters)\n\u001B[1;32m    146\u001B[0m is_stream \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_stream:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/dashscope/client/base_api.py:145\u001B[0m, in \u001B[0;36mBaseApi.call\u001B[0;34m(cls, model, input, task_group, task, function, api_key, workspace, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m request \u001B[38;5;241m=\u001B[39m _build_api_request(model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    138\u001B[0m                              \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    139\u001B[0m                              task_group\u001B[38;5;241m=\u001B[39mtask_group,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    142\u001B[0m                              api_key\u001B[38;5;241m=\u001B[39mapi_key,\n\u001B[1;32m    143\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    144\u001B[0m \u001B[38;5;66;03m# call request service.\u001B[39;00m\n\u001B[0;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m request\u001B[38;5;241m.\u001B[39mcall()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/dashscope/api_entities/http_request.py:83\u001B[0m, in \u001B[0;36mHttpRequest.call\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (item \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m response)\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 83\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(response)\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28mnext\u001B[39m(response)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/dashscope/api_entities/http_request.py:302\u001B[0m, in \u001B[0;36mHttpRequest._handle_request\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    301\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(e)\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/dashscope/api_entities/http_request.py:285\u001B[0m, in \u001B[0;36mHttpRequest._handle_request\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    284\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRequest body: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m obj)\n\u001B[0;32m--> 285\u001B[0m         response \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mpost(url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl,\n\u001B[1;32m    286\u001B[0m                                 stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream,\n\u001B[1;32m    287\u001B[0m                                 json\u001B[38;5;241m=\u001B[39mobj,\n\u001B[1;32m    288\u001B[0m                                 headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders},\n\u001B[1;32m    289\u001B[0m                                 timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout)\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod \u001B[38;5;241m==\u001B[39m HTTPMethod\u001B[38;5;241m.\u001B[39mGET:\n\u001B[1;32m    291\u001B[0m     response \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mget(url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl,\n\u001B[1;32m    292\u001B[0m                            params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mparameters,\n\u001B[1;32m    293\u001B[0m                            headers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    294\u001B[0m                            timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:637\u001B[0m, in \u001B[0;36mSession.post\u001B[0;34m(self, url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    627\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 637\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/adapters.py:589\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    586\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    588\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 589\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[1;32m    590\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    591\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m    592\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[1;32m    593\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    594\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    595\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    596\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    597\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    598\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[1;32m    599\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m    600\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    601\u001B[0m     )\n\u001B[1;32m    603\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    604\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[1;32m    790\u001B[0m     conn,\n\u001B[1;32m    791\u001B[0m     method,\n\u001B[1;32m    792\u001B[0m     url,\n\u001B[1;32m    793\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[1;32m    794\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[1;32m    795\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m    796\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    797\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[1;32m    798\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[1;32m    799\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[1;32m    800\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[1;32m    802\u001B[0m )\n\u001B[1;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:464\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 464\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    467\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1428\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1428\u001B[0m         response\u001B[38;5;241m.\u001B[39mbegin()\n\u001B[1;32m   1429\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1430\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/http/client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_status()\n\u001B[1;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/http/client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mreadline(_MAXLINE \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    706\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    710\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1252\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1250\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1251\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[1;32m   1253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1104\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1106\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import dashscope\n",
    "\n",
    "# Load environment variable (DASHSCOPE_API_KEY)\n",
    "load_dotenv(\"dashscope_api_key.env\")\n",
    "api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"‚ùå DASHSCOPE_API_KEY not found!\")\n",
    "\n",
    "def call_model(\n",
    "    prompt: str,\n",
    "    model_name: str,\n",
    "    system_prompt: str = (\n",
    "        \"You are a helpful assistant. \"\n",
    "        \"Please show your reasoning step by step (Chain of Thought). \"\n",
    "        \"Then, on a new line at the end, write: 'Final Answer: <the result>'.\"\n",
    "    ),\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 0.9,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: float = 0.3\n",
    ") -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Call the first model and return the full text response along with usage info.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    for attempt in range(max_retries):\n",
    "        response = dashscope.Generation.call(\n",
    "            api_key=api_key,\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            result_format=\"message\"\n",
    "        )\n",
    "        status_code = response.get(\"status_code\", None)\n",
    "        if status_code == 429:\n",
    "            print(f\"‚è≥ [Attempt {attempt+1}/{max_retries}] Rate limit! Waiting {retry_delay}s...\")\n",
    "            time.sleep(retry_delay)\n",
    "            continue\n",
    "        try:\n",
    "            content = response[\"output\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            usage = response.get(\"usage\", {})\n",
    "            return content, usage\n",
    "        except (TypeError, KeyError, IndexError):\n",
    "            print(f\"‚ö†Ô∏è [Attempt {attempt+1}/{max_retries}] Unexpected structure:\\n{response}\")\n",
    "            time.sleep(retry_delay)\n",
    "    print(\"‚ùå All attempts failed, returning empty result.\")\n",
    "    return \"\", {}\n",
    "\n",
    "\n",
    "def judge_answers(\n",
    "    responses_texts: list[str],\n",
    "    reference_answer: str,\n",
    "    judge_model: str,\n",
    "    system_prompt: str = (\n",
    "        \"You are a strict and precise mathematical judge.\\n\\n\"\n",
    "        \"You are given 5 responses generated by a model, and the correct reference answer (in LaTeX).\\n\\n\"\n",
    "        \"Your task is to:\\n\"\n",
    "        \"1. Determine the majority answer ‚Äî the most frequently occurring final answer across the responses. \"\n",
    "        \"   - If there is a tie (i.e., two or more answers occur with the same highest frequency), select the one that appears first.\\n\"\n",
    "        \"   - If all 5 responses are different (i.e., no answer occurs more than once), select the final answer from the first response.\\n\"\n",
    "        \"2. Compare this majority answer to the reference answer.\\n\"\n",
    "        \"3. If the majority answer matches the reference answer, then Correct = True; otherwise, False.\\n\"\n",
    "        \"4. Identify the indices (starting from 1) of all responses that produced the majority answer (regardless of whether it's correct).\\n\\n\"\n",
    "        \"Respond in **exactly** this format:\\n\"\n",
    "        \"Correct: True or False\\n\"\n",
    "        \"SelectedIndices: <comma separated indices, e.g., 1,2,3>\\n\\n\"\n",
    "        \"Respond with exactly those two lines. Do not include any extra explanation or reasoning.\"\n",
    "    ),\n",
    "    temperature: float = 0.0,\n",
    "    top_p: float = 1.0,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: float = 0.3\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Return both correctness, a confidence score, and the indices (1-indexed) of the responses\n",
    "    that are considered as the majority answer.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    user_prompt = f\"Reference answer (LaTeX): {reference_answer}\\n\\n\"\n",
    "    user_prompt += f\"Below are {len(responses_texts)} responses from the model:\\n\"\n",
    "    for i, text in enumerate(responses_texts, start=1):\n",
    "        user_prompt += f\"\\n--- Response {i} ---\\n{text}\\n\"\n",
    "    user_prompt += (\n",
    "        \"\\nQuestion: Are the majority of these responses correct?\\n\"\n",
    "        \"Respond in the format:\\n\"\n",
    "        \"Correct: True or False\\n\"\n",
    "        \"Confidence: <float>\\n\"\n",
    "        \"SelectedIndices: <comma separated indices (starting from 1)>\\n\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        response = dashscope.Generation.call(\n",
    "            api_key=api_key,\n",
    "            model=judge_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            result_format=\"message\"\n",
    "        )\n",
    "        try:\n",
    "            text = response[\"output\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (TypeError, KeyError, IndexError):\n",
    "            time.sleep(retry_delay)\n",
    "            continue\n",
    "\n",
    "        print(f\"Judge Text:{text}\")\n",
    "        \n",
    "        match = re.search(r\"Correct:\\s*(True|False)\", text, flags=re.IGNORECASE)\n",
    "        # conf_match = re.search(r\"Confidence:\\s*([0-1](?:\\.\\d+)?)\", text)\n",
    "        sel_match = re.search(r\"SelectedIndices:\\s*([\\d,\\s]+)\", text)\n",
    "        \n",
    "        if match and sel_match:\n",
    "            is_correct = match.group(1).strip().lower() == \"true\"\n",
    "            # confidence = float(conf_match.group(1))\n",
    "            selected_indices_str = sel_match.group(1).strip()\n",
    "            try:\n",
    "                # transform selected indices string to int list\n",
    "                selected_indices = [int(idx.strip()) for idx in selected_indices_str.split(\",\") if idx.strip().isdigit()]\n",
    "            except ValueError:\n",
    "                selected_indices = []\n",
    "            return {\"correct\": is_correct, \"confidence\": confidence, \"selected_indices\": selected_indices}\n",
    "    print(\"‚ùå judge_answers: failed all retries.\")\n",
    "    return {\"correct\": False, \"confidence\": 0.0, \"selected_indices\": []}\n",
    "\n",
    "\n",
    "\n",
    "# Load the MATH-500 dataset (CSV file with fields: unique_id, subject, level, problem, solution, answer)\n",
    "data_path = \"dataset/MATH-500/math500_processed.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "num_samples = 20  # Set to -1 to use the full dataset; set to a positive number to limit sample size\n",
    "subset = df if num_samples == -1 else df.head(num_samples)\n",
    "\n",
    "# List of initial models to evaluate (used to generate responses)\n",
    "models_to_test = [\"qwen2.5-math-1.5b-instruct\"]\n",
    "\n",
    "# The second (judge) model believed to be more reliable\n",
    "judge_model = \"deepseek-v3\"  # Replace this with the actual judge model name\n",
    "\n",
    "# Global parameters\n",
    "temperature = 0.7\n",
    "top_p = 0.9\n",
    "samples_per_question = 5\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n\\n==================== Evaluating Model: {model_name} ====================\")\n",
    "    model_short_names = {\"qwen2.5-math-1.5b-instruct\": \"qwen\"}\n",
    "    dataset_name = \"math500\"\n",
    "    short_name = model_short_names.get(model_name, model_name.replace(\"/\", \"_\"))\n",
    "    save_path = f\"results/self_consistency_{dataset_name}_{short_name}.csv\"\n",
    "\n",
    "    # Resume mode: check if result file exists and read already processed indices\n",
    "    done_indices = set()\n",
    "    if os.path.exists(save_path):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(save_path)\n",
    "            done_indices = set(existing_df[\"index\"].tolist())\n",
    "            print(f\"üîÅ Resuming from existing result file: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to read existing result file: {e}\")\n",
    "\n",
    "    # Iterate through each question in the dataset\n",
    "    for idx, row in subset.iterrows():\n",
    "        if idx in done_indices:\n",
    "            continue\n",
    "\n",
    "        question = row[\"problem\"]\n",
    "        gold_answer = row[\"answer\"]\n",
    "\n",
    "        print(f\"\\n=== Evaluating question at index {idx} ===\")\n",
    "        print(\"Question:\", question)\n",
    "\n",
    "        # Collect multiple responses from the model along with usage info\n",
    "        responses_texts = []\n",
    "        usages = []\n",
    "        for sample_i in range(samples_per_question):\n",
    "            try:\n",
    "                output, usage = call_model(\n",
    "                    prompt=question,\n",
    "                    model_name=model_name,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[Error in call_model] {e}\")\n",
    "                output = \"\"\n",
    "                usage = {}\n",
    "            responses_texts.append(output)\n",
    "            usages.append(usage)\n",
    "        \n",
    "        # Build a dictionary to store token usage info per response (1-indexed)\n",
    "        usage_dict = {i+1: usages[i] for i in range(len(usages))}\n",
    "\n",
    "        # Use the judging model to determine correctness and get selected response indices\n",
    "        judgement = judge_answers(\n",
    "            responses_texts=responses_texts,\n",
    "            reference_answer=gold_answer,\n",
    "            judge_model=judge_model,\n",
    "            temperature=0.0,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        is_correct = judgement[\"correct\"]\n",
    "        selected_indices = judgement.get(\"selected_indices\", [])\n",
    "        confidence = len(selected_indices) / 5\n",
    "        \n",
    "        # Compute the average length (in characters) of the selected responses\n",
    "        selected_responses = [\n",
    "            responses_texts[sel_idx - 1] for sel_idx in selected_indices if sel_idx - 1 < len(responses_texts)\n",
    "        ]\n",
    "        if selected_responses:\n",
    "            response_length = sum(len(resp) for resp in selected_responses) / len(selected_responses)\n",
    "            response_length = int(response_length)\n",
    "        else:\n",
    "            response_length = 0\n",
    "\n",
    "        # Compute average token usage across all responses\n",
    "        if usages:\n",
    "            total_completion_tokens = 0\n",
    "            total_prompt_tokens = 0\n",
    "            total_total_tokens = 0\n",
    "            for usage in usages:\n",
    "                total_completion_tokens += usage.get(\"output_tokens\", usage.get(\"completion_tokens\", 0))\n",
    "                total_prompt_tokens += usage.get(\"input_tokens\", usage.get(\"prompt_tokens\", 0))\n",
    "                total_total_tokens += usage.get(\"total_tokens\", 0)\n",
    "            n = len(usages)\n",
    "            completion_tokens = int(total_completion_tokens / n)\n",
    "            prompt_tokens = int(total_prompt_tokens / n)\n",
    "            total_tokens = int(total_total_tokens / n)\n",
    "        else:\n",
    "            completion_tokens = 0\n",
    "            prompt_tokens = 0\n",
    "            total_tokens = 0\n",
    "\n",
    "        # Create result dictionary for this example\n",
    "        result_row = {\n",
    "            \"index\": idx,\n",
    "            \"gold_answer\": gold_answer,\n",
    "            \"correct\": is_correct,\n",
    "            \"response_length\": response_length,\n",
    "            \"confidence\": confidence,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "            \"total_tokens\": total_tokens,\n",
    "        }\n",
    "\n",
    "        # Write the result immediately to the CSV file (supports resuming)\n",
    "        write_header = not os.path.exists(save_path)\n",
    "        with open(save_path, mode='a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=result_row.keys())\n",
    "            if write_header:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(result_row)\n",
    "\n",
    "        print(f\"‚úÖ Saved result for index {idx}: {'Correct' if is_correct else 'Incorrect'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
